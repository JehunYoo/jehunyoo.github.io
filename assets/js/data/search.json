[ { "title": "Docker 첫 사용기 - MySQL 사용하기", "url": "/posts/docker-mysql/", "categories": "Docker", "tags": "docker, mysql", "date": "2024-01-20 19:00:00 +0900", "snippet": "Introduction최근에 MySQL을 프로젝트에서 사용하기로 결정하기도 했고, MySQL에 대해 깊이 있게 공부하기 위해서 맥북에 설치가 필요했다. 그냥 로컬에 설치하는건 어렵지 않지만 MariaDB도 설치해야 하는 경우에 애를 먹었던 기억이 있어서 다른 방법으로 설치를 하고 싶었다. (정확하지는 않지만) 두 데이터베이스가 설치 경로를 공유하는 문제였던 것으로 기억한다.그래서 생각해낸 방법이 Docker이다. Docker를 사용하면 심지어 두 데이터베이스를 필요에 따라 동시에 사용할 수도 있을 것이다.Docker에 대해서 간단하게Docker image와 container에 대해서 간단하게 설명해보겠다. image는 어떤 애플리케이션을 위한 환경을 모두 담아둔 것이다. container는 이 image를 바탕으로 호스트에서 동작하는 프로세스다.따라서 나는 MySQL Docker image를 통해 container를 구성하고 필요할 때마다 MySQL을 사용할 계획이다. 만약 나중에 MariaDB를 사용해야 한다면, 마찬가지로 MariaDB Docker image를 통해 container를 구성하고 필요할 때마다 MariaDB를 사용할 수 있다. 만약 동시에 사용할 일이 생긴다면, 포트 포워딩 정도만 수정해주면 간단하게 해결될 것이다.Docker로 MySQL 사용하기Docker가 설치되어 있다고 가정한다. $ docker pull mysql:&lt;tag&gt; MySQL Docker 이미지를 다운로드 한다. 이때 원하는 tag를 지정할 수 있다. 지정하지 않으면 latest이다. $ docker images 이미지 대한 정보를 확인할 수 있다. $ docker run --name &lt;container-name&gt; -e MYSQL_ROOT_PASSWORD=&lt;password&gt; -d -p 3306:3306 mysql:&lt;tag&gt; run 명령어로 Docker 컨테이너를 실행한다. 이때 어떤 이미지를 기반으로 할지 tag와 함께 명시한다. --name 옵션으로 컨테이너의 이름을 부여할 수 있다. -e 옵션으로 환경변수를 지정할 수 있다. 여기서는 root user가 사용할 비밀번호를 지정했다. -d 옵션으로 컨테이너를 백그라운드에서 (detached) 실행할 수 있다. 실행 결과로 container id를 출력한다. -p 옵션으로 포트포워딩을 설정할 수 있다. 호스트의 3306 포트를 컨테이너 내부의 3306 포트로 포워딩 해준다. $ docker ps -a ps 명령어로 컨테이너 목록을 조회할 수 있다. -a 옵션으로 백그라운드 컨테이너도 함께 조회할 수 있다. $ docker exec -it &lt;container-id&gt; bash -i 옵션으로 stdin을 활성화하고 컨테이너가 attach되어있지 않아도 stdin을 유지할 수 있다. bash에 명령을 입력하기 위해 사용한다. -t 옵션으로 TTY 모드를 사용할 수 있다. 이 옵션을 사용하지 않으면 명령을 입력할 수는 있어도 shell이 표시되지 않는다. 위의 두 옵션을 하나로 합쳐서 -it로 많이 사용한다. exec 명령어는 실행되고 있는 컨테이너에 작업을 할 때 사용된다. 따라서 container id가 필요하다. 접속된 상태에서 $ mysql -u root -p MySQL 컨테이너에 접속한 상태에서 MySQL을 사용하는 것이다. 다음은 컨테이너를 중지 / 시작 / 재시작하는 명령어이다. $ docker stop &lt;container-id&gt; $ docker start &lt;container-id&gt; $ docker restart &lt;container-id&gt; -e MYSQL_ROOT_PASSWORD=&lt;password&gt;를 사용하지 않으면 어떻게 될까?처음에 굳이 필요하지 않을 수도 있겠다고 생각해서 사용하지 않았었다. docker run --name &lt;container-name&gt; -d -p 3306:3306 mysql:&lt;tag&gt;를 실행했는데, 에러가 나지는 않았다. 그러나 이후에 docker exec -it &lt;container-id&gt; baash를 실행하려고 하는데 다음과 같은 메시지가 나왔다.Error response from daemon: Container is not running난 분명히 방금 docker run으로 컨테이너를 실행했는데 무슨 소린가 싶어서 docker ps -a로 현재 컨테이너의 상태를 확인했다.STATUSExited (1) 8 seconds ago내가 생각한대로 컨테이너가 정상적으로 동작하지 않고 바로 종료된 것이다. 구글링을 해보니 도커 컨테이너는 컨테이너가 작업할 것이 없으면 즉시 종료된다고 한다. 이를 통해 MySQL 서버가 종료되었음을 추측할 수 있었고, 컨테이너를 실행하는 과정에서 문제가 있었다고 생각했다. 그래서 처음에 사용하지 않았던 -e 옵션으로 환경 변수 MYSQL_ROOT_PASSWORD를 정의해주었더니 문제가 해결되었다.MySQL Docker Container를 종료하면 DB에 저장된 데이터가 사라질까?테스트를 해보기 위해 위와 같이 컨테이너를 실행시키고, MySQL에 접속해서 새로운 데이터베이스, 테이블, 데이터를 추가했다. 이후에 docker stop으로 해당 컨테이너를 중지시키고 docker start로 시작시키고 MySQL에 접속해서 확인해봤다.그 결과, 데이터가 그대로 남아있었다!" }, { "title": "[Waffle] 스프링 프로젝트 구조 설계하기", "url": "/posts/waffle-spring-project-architecture/", "categories": "Waffle", "tags": "waffle, spring", "date": "2023-10-23 23:02:00 +0900", "snippet": "현재 상황구현해야 하는 것 Member, Waffle, Comment CRUD Auth (회원가입, 로그인, 로그아웃)DB 테이블 설계 Member, Waffle, Comment + 기타 테이블패키지 구조 정하기검색해보니 패키지 구조에는 크게 2가지 경우가 있었다. 계층형 도메인형도메인형 구조는 도메인 별로 패키지를 분리한다. 독립적인 코드를 작성하는 것에 유리하다고 생각해서 도메인형 패키지 구조를 사용하기로 했다.프로젝트 구조 설계하기스프링 프레임워크를 사용하는 만큼 객체 지향 프로그래밍에 맞게 설계를 하고 싶었다. 특히 객체들이 하나의 책임만을 갖고 (SRP), 구체화보다는 추상화에 의존하면서 (DIP), 확장에는 열려있으나 변경에는 닫혀있는 (OCP) 설계를 원했다. 그래서 계층을 나누고 계층에 해당하는 객체에 하나의 역할만 부여하고자 했다.계층 나누기계층(layer)은 크게 다음 4가지로 나눌 수 있다. Presentation Layer - Controller, ControllerAdvice Business Layer - Service Persistence Layer - Repository, DAO Database Layer - DB각 계층은 순차적으로 연결되며, 다른 계층이 어떻게 구현되어 있는지 알지 말아야 한다. 이렇게 의존성을 줄임으로써 각 계층의 역할이 명확해지고 특정 계층에 변화가 생겼을 때 영향을 적게 받는다.의존성을 줄이기 위해 추가로 다양한 방법을 적용했다. 서비스 로직과 DB 로직 분리하기 DAO를 테이블에 1:1로 매핑하기 Service에서 호출하는 Persistence Layer의 메서드 이름을 어떻게보다 무엇을 하는지에 초점 맞추기역할 부여하기각각의 객체는 하나의 역할만 수행한다. Controller: 클라이언트 요청 받기 ControllerAdvice: 예외 처리하기 Service: 서비스 로직 수행하기 Repository: DB 로직 수행하기 DAO: 매핑된 테이블에 대한 요청 처리하기추가로 다음과 같은 객체도 있다. DTO: 클라이언트 요청 운반하기 Validator: 클라이언트 요청 검증하기 Converter: DTO &lt;-&gt; entity 변환하기 (직접 정의한 객체이다. 스프링이 제공하는 ConversionService로 대체 예정)특별히 DAO는 테이블에 1대1로 매핑되어 해당 테이블에 대한 원자적인 요청을 처리한다. 다음의 메서드를 CrudDao 인터페이스로 만들어둬서 CRUD가 필요한 다른 도메인에서도 구현하도록 강제했다. DAO.save() DAO.findById() DAO.delete()이 방법의 장점은 도메인이 여러 개일 때 나타난다. 복수의 Repository에서 같은 테이블에 접근하는 경우를 생각해보자. 이때 접근 방법이 다양하면 관리도 힘들고 변경이 발생했을 때 관리하기 힘들 것이다.DAO를 사용함으로써 원하는 테이블의 DAO만 알면 해당 테이블에 대한 요청을 간단하게 보낼 수 있다.추가로 DB가 어떻게 설계되어 있는지 Service가 알지 못하게 할 수 있다. 만약 Waffle을 조회해야하는 경우 Comment도 같이 조회를 해야한다면, WaffleService는 waffleRepository.findAll(), commentRepository.findAll()을 호출해야 한다. 이때 WaffleRepository가 DB 로직을 분리하여 해당 작업을 책임진다면 WaffleService는 waffleRepository.findAll()만 호출할 수 있다. 동시에 DB의 구조를 숨길 수 있게된다.DTO는 어디까지 내려갈까?검증이 끝난 DTO는 어느 계층까지 내려보내야 할까? 검색해보니 일반적으로 Service에서 Entity로 변환하는 것 같다. 모든 DTO를 Service에서 변환하면 좋겠지만 그럴 수 없는 경우도 있다. 불필요하게 미리 변환하게 되면 요청이 변경되었을 때 영향을 받는 계층이 많아지므로 최대한 필요한 순간에 변환하기로 했다. 다만, 그 하한선은 Repository로 제한했다." }, { "title": "Java Interface - 객체 지향 프로그래밍의 관점에서", "url": "/posts/java-interface-oop/", "categories": "Java", "tags": "java, oop", "date": "2023-10-22 23:25:00 +0900", "snippet": "객체들의 소통 방식객체 지향 프로그래밍에서 객체들은 어떻게 소통할까?객체들은 각자 주어진 역할이 있고 그 역할을 수행하기 위한 책임을 갖는다. 객체들이 역할을 성실히 수행하면 하나의 커다란 애플리케이션을 완성할 수 있다.객체들이 역할을 성실하게 수행하기 위해서는 자신들만의 명확한 역할과 책임을 가져야 한다. 따라서 다른 역할과 책임을 갖는 객체에 의존적이지 않아야 한다. 또한 객체들은 서로가 필요할 때 서로에게 요구사항을 전달할 수 있어야 한다.요구사항을 전달하는 것은 여러 단어로 말할 수 있을 것 같다. 요청 소통 협력어떻게 서로 소통하는지에 대한 생각은 잠시 미뤄두고, 무엇을 소통할 수 있는지 생각해보자.인터페이스란?위키백과에는 인터페이스를 다음과 같이 설명한다. 인터페이스는 서로 다른 두 개의 시스템, 장치 사이에서 정보나 신호를 주고받는 경우의 접점이나 경계면이다.우리는 다음과 같이 바꿔보자. 인터페이스는 서로 다른 두 객체 사이에서 요청을 주고받는 접점이다.인터페이스는 두 객체 사이의 접점이다. (두! 객! 체!)(예전에 서른명 정도 앞에서 인터페이스에 대해 발표할 일이 있었다. 그때는 Java를 처음 공부할 때여서 다음과 같이 말했다. ‘서로 관련이 없는 클래스라도 인터페이스에 정의된 기능을 구현하고 싶으면 사용한다.’ 뭔가 껍데기만 있는 느낌이다.)Java에서 인터페이스는 추상 메서드를 갖는다. 위의 정의를 바탕으로 추상 메서드는 다음처럼 설명할 수 있을 것 같다. 추상 메서드는 해당 인터페이스를 구현한 객체에게 무엇을 요청할 수 있는지를 나타낸다.인터페이스 I를 구현한 객체 A에게 인터페이스 I를 구현하지 않은 어떤 객체 B가 요청을 보내기 위해서는 인터페이스 I만 알면 된다. 심지어 객체 A에 대한 구현 클래스도 몰라도 된다. 객체 지향 프로그래밍 측면에서는 모를수록 좋을 것이다.비유하자면 일종의 메뉴판 같은 것이다. 우리는 식당에 가서 메뉴판을 보고 주문을 한다. 일반적으로 메뉴판에는 요리 방법이 쓰여있지는 않다. 다만 우리는 메뉴판에 있는 음식 이름과 가격을 보고 주문한다.public interface Menu { public abstract Pasta orderPasta(int price); public abstract Risotto orderRisotto(int price); public abstract Steak orderSteak(int price);}우리는 메뉴판을 보고 어떤 요청이 있고, 각각의 요청에는 어떤 것들이 필요하고, 무엇을 얻을 수 있는지 알 수 있다.왜 public일까?위의 Menu에서 public과 public abstract를 생략할 수 있다.Java는 왜 생략 가능하게 만들었을까? 다르게 생각하면, Java는 왜 인터페이스에 public, public abstract를 자동으로 붙여줄까?이렇게 함으로써 Java는 인터페이스를 public으로만 사용할 수 있고 public인 추상 메서드만 정의할 수 있게 강제한다.만약 추상 메서드가 private인 경우를 생각해보자. 이런 경우 다른 객체는 해당 메서드를 호출할 수 없다. 이 말은 다른 객체와 소통할 때 사용할 수 없다는 뜻이다. 따라서 public이 아닌 메서드는 ‘어떻게’의 영역이라고 할 수 있다. private interface의 경우도 마찬가지이다.private interface Menu { private abstract Pasta orderPasta(int price); private abstract Risotto orderRisotto(int price); private abstract Steak orderSteak(int price);}음식을 시킬 수도 없고, 심지어 음식점인지도 모를 것이다.default methoddefault method는 조금 다른 이야기이다. Java 8부터 추가된 기능인데 인터페이스에 정의되는 메서드임에도 구현체가 있다. 간단하게만 설명해보겠다.인터페이스를 구현한 클래스는 항상 모든 추상 메서드를 구현해야한다. 그렇지 않다면 다른 객체가 보기에는 이상할 것이다. 요청에 응답할 수도 없으면서 가능하다고 인터페이스에 명시해둔 셈이 된다.이때 기존의 인터페이스에 새로운 추상 메서드를 추가하고 싶다면 어떤 문제가 발생할까? 정말 끔찍하게도 해당 인터페이스를 구현한 모든 클래스에 새로 추가된 추상 메서드를 새롭게 구현해야한다.그래서 Java 개발자들은 기존의 구현을 고치지 않고도 인터페이스를 변경할 수 있는 방법을 고민했다. 그에 대한 결론은 default method인 것이다. default method는 구현하지 않아도 된다.마치며한달 전부터 정리해보고 싶은 글이었는데 드디어 작성한다!Java를 처음 공부하면서 인터페이스를 접했을 때 많이 생소했다. Java는 왜 인터페이스라는 것을 제공하는지도 몰랐고 잘 이해가 가지 않았다.그러나 OOP에 대해 공부를 하고 OOP를 잘 활용할 수 있게 도와주는 Spring을 공부하고 보니 비로소 조금씩 감을 잡는 것 같다. Java를 공부하면서 가장 재밌는 깨달음이었다. (두번째는 Enum)" }, { "title": "[Waffle] 댓글 조회 REST API 설계하기", "url": "/posts/waffle-define-comment-rest-api/", "categories": "Waffle", "tags": "waffle, rest api", "date": "2023-10-16 23:10:00 +0900", "snippet": "뭔가 이상한데?만들었던 API 명세에는 단일 댓글 조회를 이렇게 해놨다.GET /waffles/{waffleId}/comments/{commentId}여기서 waffleId, commentId가 정확히 어떤 의미인지 혼동이 왔다.저 URI가 의미가 있으려면 계층 구조를 살려서 다음과 같이 사용되야 한다고 생각했다./waffles/10/comments/2 (10번째 waffle의 2번째 댓글)path variable 자리에 몇 번째인지 의미를 부여했다.이렇게 하면 각 waffle에 대한 n번째 댓글을 요청할 수 있으므로 요청을 보낼 때도 의미가 자연스러워 보였다.구현하기/waffles/10/comments/2라는 요청을 받았다고 가정하자.어떻게 구현할 것인가?현재 DB의 comment 스키마는 다음과 같다.몇 번째 waffle인지 알고 해당 waffle의 몇 번째 댓글인 것을 알고 있기 때문에 다음과 같이 조회할 수 있다.select * from comment where waffle_id = 10 order by created_at limit 1, 1;사용자 피드에 적용하기그럼 이제 어떤 사용자가 /waffles/10/comments/2라는 요청을 보낸 상황을 생각해보자.이 요청은 어떤 사용자 A의 10번째 waffle의 2번째 댓글에 대한 요청이다.그런데 이것이 REST API 설계에 맞는 것인지 의문이 들었다.사용자 A에 대한 정보가 URI에 포함되어 있지 않기 때문이다.(수정한다면 이런 방식으로 /members/{memberId}/waffles/{waffleId}/comments/{commentId})또한 각 사용자마다 몇 번째 waffle인지에 대한 계산을 해야하는 부담도 있다.하나의 waffle에 대해 사용자마다 피드에서 보이는 순서는 모두 다를 수 있기 때문이다.여기에 더해서 매번 댓글을 조회할 때 정렬에 대한 비용이 발생할 수 있다.계층 구조 제거하기URI에서 계층 구조를 사용하지 않는다면 문제를 해결할 수 있다.예를 들어, comments/{commentId}처럼 직접 댓글을 요청하는 것이다.(그러나 이렇게 되면 몇 번째 댓글인지에 대한 정보는 더 이상 의미가 없게 된다.)요청을 처리할 때 구현은 간단해졌다.select * from comment where id = comment_id;이제 id에 순서에 대한 의미를 부여하지 말고 pk를 id로 사용하자.문제가 없는 것 같지만 아직 한 개가 남아있다.복수 댓글 조회 API와 비교복수 댓글 조회 API 명세는 다음과 같다.GET /waffles/{waffleId}/comments만약 waffle_id가 10인 (더 이상 10번째 waffle이 아니다.) waffle에 대한 모든 댓글을 조회하고 싶다면 다음과 같이 요청하는 것이 자연스럽다./waffles/10/comments심지어 이 요청에는 계층 정보가 포함되어 있다. 복수 조회: /waffles/{waffleId}/comments 단일 조회: comments/{commentId}비슷한 API임에도 전혀 다른 URI를 가지고 있다.통일감도 없고 REST API 설계에도 맞지 않아보인다.해결 방법생각했던 해결 방법은 간단하다. 복수 조회: /waffles/{waffleId}/comments 단일 조회: /waffles/{waffleId}/comments/{commentId}다만 한가지 어색한 점은 단일 조회에서 comment_id를 알기 때문에 굳이 waffle_id가 필요하지 않다는 점이다.그럼에도 굳이 추가를 한 이유는 요청의 유효성을 검증하기 위해서이다.만약 waffle_id = 10인 waffle에 대한 댓글을 조회한다고 가정하자.이때 해당 waffle과 전혀 관련없는 comment_id = 200인 댓글을 잘못 요청한 경우 서버에서 잘못된 요청임을 파악해야 한다. (404 에러를 반환할 수 있다.)이런 생각의 흐름으로 위와 같은 결론을 얻었다." }, { "title": "C CheatSheet", "url": "/posts/c-cheatsheet/", "categories": "C", "tags": "c", "date": "2020-07-29 00:00:00 +0900", "snippet": "1D Array#1int main(void){ int arr[2]; arr[0]=0, arr[1]=1, arr[2]=2;} → arr[2]=2;컴파일러는 배열 접근에 있어서 유효성 검사를 진행하지 않는다.∴ compile error 발생 X할당되지 않은 메모리 공간을 침범할 수 있으므로 주의하자.#2 Length of Arraylen = sizeof(arr) / sizeof(/* type of element */); 함수 내부에서는 배열의 길이를 구할 수 없다.함수 내부에서 argument로 받은 배열의 sizeof연산 결과는 64bit 시스템에서는 8byte, 32bit 시스템에서는 4byte이다.즉, pointer의 크기와 같다.#3 String &amp; Null (‘\\0’) 어떤 문자열 str에 대해 길이가 len이라 하자.null은 str[len]에 저장되어 있다.Pointer#1 Operator &amp; and * &amp;(operand) : operand의 주소 값 반환 *(operand) : operand가 가리키는 주소 참조 &amp;연산자는 상수를 피연산자로 사용할 수 없다.#2#include &lt;stdio.h&gt;int main(void){ int * ptr1 = 0; int * ptr2 = NULL;} 두 방식 모두 NULL pointer로 초기화 한다.주소값 0을 갖는 것이 아니라 메모리 아무데도 가리키지 않는다는 의미이다.Pointer &amp; Array#1 상수 형태의 pointerint arr[3] = {0, 1, 2};arr = &amp;arr[i]; // for i in [0, 1, 2] 배열 arr는 상수 형태의 pointer 이다.따라서 arr에 저장되어 있는 주소 값을 변경 할 수 없다.arr = &amp;arr[i]는 compile error를 발생시킨다.#2 문자열 상수 &amp; 문자열 변수char str1[] = \"Hello, World!\";char * str2 = \"Hello, World!\"; str1 : pointer 상수 → 문자열 변수 (문자열 변경 가능) str2 : pointer 변수 → 문자열 상수 (문자열 변경 불가) str1[12] = '?'; // 문자열 변경 가능str2[12] = '?'; // 문자열 변경 불가 위의 코드는 컴파일은 되지만 실행은 안된다.문제가 발생하는 형태는 컴파일러나 컴파일 모드에 따라서 프로그램이 종료되거나 문제가 있는 코드를 무시하는 등 약간씩 차이가 있다.#3 Size of Pointer Arrayint * arr1[100];double * arr2[100]; 64bit 시스템 (size of pointer = 8byte) 기준 sizeof(arr1) = sizeof(int *) × 100 = 800byte sizeof(arr2) = sizeof(double *) × 100 = 800byte 두 배열의 크기가 같다!#4 Array of String문자열 하나를 변수 str에 저장char * str = \"Hello, World!\";// ORchar str[] = \"Hello, World!\";문자열 여러개를 문자열 배열 str에 저장char * str[] = {\"Hello\", \"World!\"}; 큰따옴표로 묶여서 표현되는 문자열은 그 형태에 상관없이 메모리 공간에 저장된 후 그 주소 값이 반환된다. C에서 문자열을 메모리 주소 값으로 다루기 때문에 문자열 배열 원소의 자료형은 char *이다.#5 Array of String 2char c = 'c'; // Characterchar * str = \"Hello, World!\"; // String = Pointerchar arrc[] = {'a', 'b', 'c'}; // Array of Characterchar * arrs[] = {\"Hello\", \"World!\"}; // Array of String = Array of Pointer Data Types Character : char String : char * Array of Character (≒ String) : collection of char Array of String : collection of char * Array of Characters → There’s no null character. String → There is null character. Pointer &amp; Function#1 C에서 함수의 호출 방식은 기본적으로 call-by-value이다.pointer를 사용해서 call-by-reference 방식으로 호출하는 것을 메모리 주소 값을 argument로 주어 call-by-value로 호출했다고 생각할 수 있다.그렇기 때문에 pointer를 argument로 주었다고 해서 혹은 parameter가 pointer라고 해서 무조건 call-by-reference가 아니다.pointer에 대해 call-by-reference가 되게 하려면 double pointer를 사용해야 한다.#2 배열을 함수의 argument로 전달하는 방법void function1(int arr[]);void function2(int * arr); 함수의 parameter를 선언할 때에 한해서 int * arr을 int arr[]로 대체할 수 있다.int가 아닌 다른 자료형도 물론 가능하다.#3void function(int arr[]){ int size = sizeof(arr); printf(\"%d\\n\", size);}8 64bit 기준으로 8byte이다.#4 scanf scanf 함수는 call-by-reference 호출 방식을 사용한다.argument로 메모리 주소 값을 전달해 주어야 하기 때문에 일반적인 변수의 경우 &amp; 연산자를 사용한다.#5 const 1int num = 1;const int * ptr = &amp;num;*ptr = 100; // compile error ptr에 저장된 메모리 주소 값을 참조하여 그 곳에 저장된 값을 변경하는 것을 허용하지 않는다.다만 ptr을 통해 값을 변경하는 방법만 허용되지 않고 num을 통해 값을 변경하는 것은 가능하다.#6 const 2int num1 = 1, num2 = 2;int * const ptr = &amp;num1;ptr = &amp;num2; // compile error ptr을 pointer 상수로 만든다.int arr[2];에서의 arr과 같은 형태의 pointer 상수이다.따라서 ptr에 다른 주소 값을 대입하면 compile error가 발생한다.int num1 = 1;const int * const ptr = &amp;num; 위와 같은 선언도 가능하다.#8 const 3void printAllElement(const int * arr, int len){ for(int i=0; i&lt;len; i++) printf(\"%d\\n\", *(arr + i));} const의 사용은 프로그램의 안정성을 높여주는 장점이 있다.void printAllElement(const int * arr, int len){ int * ptr = arr; // warning message for(int i=0; i&lt;len; i++) printf(\"%d\\n\", *(arr + i));} int * ptr = arr;에서 warning message가 발생한다.Multi-Dimensional Array#1#include &lt;stdio.h&gt;int main(void){ int arr[5][5] = {0}; for (int i=0; i&lt;5; i++) { for(int j=0; j&lt;5; j++) printf(\"%d \", arr[i][j]); printf(\"\\n\"); } return 0;}0 0 0 0 00 0 0 0 00 0 0 0 00 0 0 0 00 0 0 0 0 int arr[5][5] = {0};와 같은 방법으로 다차원 배열도 한번에 0으로 초기화할 수 있다.#2int arr[3][2]; 위와 같이 선언된 3 × 2 배열에 대해 메모리는 다음과 같은 순서로 할당된다. &amp;arr[0][0] = 0x7ffee1178b00 &amp;arr[0][1] = 0x7ffee1178b04 &amp;arr[1][0] = 0x7ffee1178b08 &amp;arr[1][1] = 0x7ffee1178b0c &amp;arr[2][0] = 0x7ffee1178b10 &amp;arr[2][1] = 0x7ffee1178b14 sizeof(int)의 간격으로 할당되었다.#3int arr[3][3] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};int arr[3][3] = {{1}, {4, 5}, {7, 8, 9}};int arr[3][3] = {1, 2, 3, 4, 5, 6, 7}; 모두 가능한 초기화 방식이다.부족한 부분은 0으로 초기화 된다.#4int arr1[][3] = {1, 2, 3, 4, 5, 6};int arr2[][2] = {1, 2, 3, 4, 5, 6}; 배열의 세로 길이만 생략이 가능하다.Double Pointer#1**dtpr == *(*dptr); // true#2#include &lt;stdio.h&gt;int main(void){ int num1 = 10; double num2 = 10.1; int * ptr1 = &amp;num1; double * ptr2 = &amp;num2; int ** dptr1 = &amp;ptr1; double ** dptr2 = &amp;ptr2; printf(\"%p %p\\n\", ptr1, ptr2); printf(\"%p %p\\n\", dptr1, dptr2); return 0;}0x7ffee1984b18 0x7ffee1984b100x7ffee1984b08 0x7ffee1984b00 우연히 메모리에 연속적으로 할당되었다.어찌되었건 pointer의 크기는 8byte이다. (for 64bit system)pointer의 크기가 8byte임에 착안하여 ptr1과 ptr2의 주소를 각각 double **, int **형 double pointer 변수에 대입하면 어떻게 될까?#include &lt;stdio.h&gt;int main(void){ int num1 = 10; double num2 = 10.1; int * ptr1 = &amp;num1; double * ptr2 = &amp;num2; int ** dptr1 = &amp;ptr1; double ** dptr2 = &amp;ptr2; double ** dptr11 = &amp;ptr1; int ** dptr22 = &amp;ptr2; printf(\"%p %p\\n\", ptr1, ptr2); printf(\"%p %p\\n\", dptr1, dptr2); printf(\"%p %p\\n\", dptr11, dptr22); printf(\"%p %p\\n\", *dptr11, *dptr22); return 0;}0x7ffee1984b18 0x7ffee1984b100x7ffee1984b08 0x7ffee1984b000x7ffee1984b08 0x7ffee1984b000x7ffee1984b18 0x7ffee1984b10 int *, double * 모두 8byte의 크기이기 때문에 결과가 같게 나오는 것 같다.그럼 num1, num2의 값을 참조해보면 어떻게 될까?printf(\"%d %f\\n\", **dptr11, **dptr22); // warning messageprintf(\"%f %d\\n\", **dptr11, **dptr22);858993459 0.0000000.000000 858993459 두 문장을 추가했다.물론 num1과 num2의 값을 올바르게 참조할 수는 없다.흥미로운 점은 첫번째 줄에서만 warning이 발생했다는 것이다.어찌보면 강제로 주소 값을 type casting 시켰기 때문에 당연한 결과일 수 있다.그냥 궁금해서 해봤는데 이런 방법은 쓰지 말자.#3 Type of Arrayint arr1[10]; // type of arr1 = int *double arr2[10]; // type of arr2 = double *int * arr11[10]; // type of arr11 = int **double * arr22[10]; // type of arr22 = double **Pointer &amp; Multi-Dimensional Array#1#include &lt;stdio.h&gt;int main(void){ int arr[2][3]; printf(\"%p\\n\", arr); printf(\"%p\\n\", arr[0]); printf(\"%p\\n\", &amp;arr[0][0]); return 0;}0x7ffee3a7cb000x7ffee3a7cb000x7ffee3a7cb00 arr, arr[0], &amp;arr[0][0] 모두 같은 메모리 주소 값을 가리킨다.arr, arr[0]은 그 자체로 pointer이다.arr[0][0]은 index (0, 0)의 원소 값을 가리킨다.index (0, 0)의 원소의 메모리 주소는 &amp;arr[0][0]이다.#2int arr[2][3]; sizeof(arr) = sizeof(int) × 2 × 3 = 24byte sizeof(arr[0]) = sizeof(int) × 3 = 12byte arr은 arr[0][0]의 주소를 가리키면서 배열 전체를 의미한다.arr[0]은 arr[0][0]의 주소를 가리키면서 index 0행만을 의미한다.#3 arr + 1int arr1[2][3];double arr2[2][3];printf(\"%p\\n\", arr1);printf(\"%p\\n\", arr1 + 1);printf(\"%p\\n\", arr2);printf(\"%p\\n\", arr2 + 1);0x7ffee053fb000x7ffee053fb0c0x7ffee053fad00x7ffee053fae8 ∆arr1 = arr1 + 1 - arr1 = sizeof(int) × 3 = 12byte ∆arr1 = arr2 + 1 - arr2 = sizeof(int) × 3 = 24byte 배열 이름에 1을 더하면 sizeof(/* element type */) × (한 행의 element 개수)byte 만큼 주소값이 더해진다.#4arr[i][j] == *(*(arr + i) + j) // true#5 Type of Multi-Dimensional Arrayelement arr[?][num]; arr은 가리키는 대상이 element형 변수이고, pointer 연산 시 (sizeof(element) × num)byte로 증감하는 pointer type이다.#6 Declarationint arr[?][num];int (*ptr)[num] = arr;int arr[2][3];int (*ptr)[3] = arr; 앞에서 언급했듯이 다차원 배열에서 arr[0]도 pointer이다.arr[0]도 하나의 배열이라고 가정하면, 다음과 같이 생각해볼 수 있겠다.element (*ptr)[/* size of array arr[0] */] = arr;#7 Array of Pointer v. Pointer to Arrayint *arr[10]; // Array of Pointerint arr[?][10];int (*ptr)[10] = arr; // Pointer to Array Array of Pointer (포인터 배열) : pointer로 이루어진 배열 Pointer to Array (배열 포인터) : 배열을 가리키는 pointer = arr, ptr #8 Argument about Multi-Dimensional Arrayvoid function(int (*arr)[3]);// ORvoid function(int arr[][3]);int arr[2][3];function(arr);#9 *(arr + i) &amp; arr + iint arr[2][3] = {1, 2, 3, 4, 5, 6};printf(\"%p %p %p\\n\", arr + 1, arr[1], &amp;arr[1][0]);printf(\"%p %p\\n\", *(arr + 1), &amp;arr[1]);0x7ffee9e2bb0c 0x7ffee9e2bb0c 0x7ffee9e2bb0c0x7ffee9e2bb0c 0x7ffee9e2bb0c 모두 같은 주소 값을 갖고 있다.특히 arr + 1과 *(arr + 1)이 같은 값을 갖고 있다는 것이 놀라웠다.printf(\"%d\\n\", *(arr + 1)); // warning message 위의 문장은 warning을 발생시킨다.또한 warning으로부터 *(arr + 1)의 타입이 int *라는 사실을 알게되었다.printf(\"%d %d\\n\", arr[1][2], *((arr + 1) + 2)); // warning message 따라서 두 값은 다른 값으로 출력된다. 그럼 *(arr + 1)과 arr + 1의 차이가 뭘까?일부러 warning을 발생시켜 보니 다음을 알 수 있었다! *(arr + 1) : type int * arr + 1       : type int (*)[3] *(arr + 1)과 arr + 1은 가리키는 주소 값은 같지만 type이 다르다.arr + 1은 arr과 같은 int (*)[3] type이다.반면에 *(arr + 1)은 arr[1]과 같은 int * type이다.#10 arr[i] == *(arr + i)int arr[][]; // any 2D arrayarr[i] == *(arr + i); // true 앞에서 언급했듯이 다차원 배열에서 arr[i]는 pointer이다.arr[i]는 &amp;arr[i][0]와 같은 주소를 가리킨다. arr[i]가 pointer이므로 arr[i]를 어떤 배열 arri라 하자.arri는 arr의 i행의 원소들이 순서대로 들어가있다.따라서 배열 arri의 0번째 원소는 *arri이고 그 값은 arr[i][0]과 같다. arri의 타입은 int *일 것이다.따라서 배열 arri의 1번째 원소는 *(arri + 1)이 된다.또한 이때의 값은 arr[i][1], arri[1]과 같다. 이때 arri는 arr[i]이고 *(arr + i)와 같다. 여기서 *(arr + i)는 arr의 원소가 아니다.*(arr + i)는 주소를 가리키고 int * type이다.#11double * arr1[5]; // 1d array of pointer of double * typedouble * arr2[3][5]; // 2d array of pointer of double * typedouble **ptr1 = arr1;double * (*ptr2)[5] = arr2;Function Pointer &amp; Void Pointer#1int function(int param); 함수도 프로그램 실행 시에 메모리에 저장되어서 실행된다.따라서 함수의 이름 function은 함수가 저장된 메모리 주소 값을 의미한다.이때 function은 배열의 이름과 같이 pointer 상수이다.#2 Function Pointer 변수return_type function(param_type1 param1, param_type2 param2);return_type (*fptr)(param_type1, param_type2) = function; function pointer 선언과 초기화 방법이다.double function(int a, int *b);int a = 10;int *b = &amp;a;double (*fptr)(int, int *) = function;fptr(a, b) == function(a, b) // true 이를 이용하면 함수의 parameter로 function pointer 변수를 사용할 수 있다.void function2(double (*fptr)(int, int *));function2(fptr);#3 Void Pointervoid *ptr; void pointer는 변수의 종류에 상관없이 변수의 주소 값을 저장할 수 있다.그렇지만 type에 대한 정보가 없으므로 주소 값을 참조할 수 없다.#4 main Functionint main(void) {}// ORint main(int argc, char * argv[]) {} main함수의 parameter를 위와 같이 할 수도 있다.argc에는 argument의 개수가 저장된다. (파일 이름 포함)이는 아마 함수 내부에서 배열 argv의 길이를 구할 수 없기 때문에 main함수 외부에서 계산해서 넘겨주는 것 같다.argv에는 파일 이름도 포함된다.Variables#1 Local Variables 중괄호 내에 선언되는 변수 memory의 stack 영역에 할당 parameter: local variable #2 Local Variables#include &lt;stdio.h&gt;int main(void){ int i = 100; for(int i=0; i&lt;10; i++) continue; printf(\"%d\\n\", i);}100#include &lt;stdio.h&gt;int main(void){ for(int i=0; i&lt;10; i++) continue; printf(\"%d\\n\", i);}error: use of undeclared identifier 'i'printf(\"%d\\n\", i); ^#include &lt;stdio.h&gt;int main(void){ int i; for(i=0; i&lt;10; i++) continue; printf(\"%d\\n\", i);}10 변수 i의 범위에 유의하자.또한 for에 의한 반복은 중괄호의 진입과 탈출을 반복하면서 이뤄진다.#3 Global Variables 중괄호 내에서 선언되지 않는다. 별도의 값으로 초기화 하지 않으면 0으로 초기화된다. memory의 data 영역에 할당 프로그램의 시작과 동시에 할당되어 종료 시까지 존재한다. 같은 이름의 지역 변수가 지역 변수를 가리킨다. #4 Static Variables static 키워드로 선언할 수 있다. 전역 변수, 지역 변수, 함수에 static 선언을 할 수 있다. 전역 변수와 함수에 static 선언을 하면 외부 파일에서의 접근을 허용하지 않는다. 지역 변수 특성 : 선언된 함수 내에서만 접근이 가능하다. 전역 변수 특성 : 딱 1회 초기화되고 프로그램 종료 시까지 메모리 공간에 존재한다. 전역 변수와 마찬가지로 memory의 data 영역에 할당 static 변수는 접근 범위를 제한할 수 있기 때문에 전역 변수 보다 안정적이다. #include &lt;stdio.h&gt;void function(){ static int var1 = 0; // 접근 범위를 function으로 제한 / 초기화는 처음 1번만, 이후에는 이 줄이 무시되고 메모리에 저장된 값 사용 int var2 = 0; printf(\"%d %d\\n\", var1++, var2++);}int main(void){ for(int i=0; i&lt;3; i++) function(); return 0;}0 01 02 0#5 Register Variables Register : CPU 내에 존재하는 크기가 매우 작은 메모리 - Register 변수에 대한 연산이 매우 빠르다. 전역 변수에는 register 선언을 할 수 없다. register 선언을 해도 컴파일러가 합당하지 않다고 판단하면 register에 할당하지 않는다. 반대로 register 선언을 하지 않아도 컴파일러가 필요하다고 판단하면 register에 할당한다. Reference 열혈 C 프로그래밍" }, { "title": "Melon Playlist Continuation - Model 2: K Nearest Neighbor", "url": "/posts/melon-playlist-continuation-knn/", "categories": "Kakao Arena, Melon Playlist Continuation", "tags": "kakao arena, melon playlist continuation", "date": "2020-07-26 19:24:00 +0900", "snippet": "Reference[Paper] [Code] Efficient K-NN for Playlist Continuation (RecSys’18 Challenge)위의 논문을 바탕으로 KNN 모델을 만들었다.Process1. Notaion $\\mathcal{P}$ : All Playlists in train.json $\\mathcal{T}$ : All Tracks $u$ : Target Playlist in val.json or test.json $v$ : Candidate Playlist in train.json Known Track $j \\in u$ Candidate Track $i \\in v$ $s_{uv}$ : Similarity between Target Playlist $u$ and Candidate Playlist $v$ $r_{ui}$ : Relevance between Candidate Track $i$ and Target Playlist $u$ $k$, $\\rho$ : Hyperparameter2. Similarity $s_{uv}$2.1 Cosine Similarity\\[\\scriptsize{s_{uv} = \\cfrac{\\mathbf{u} \\cdot \\mathbf{v}}{\\Vert\\mathbf{u}\\Vert_2 \\Vert\\mathbf{v}\\Vert_2}}\\]OR\\[\\scriptsize{s_{uv} = \\sum_{i \\in \\mathcal{T}} \\cfrac{e_{ui}e_{vi}}{\\Vert\\mathbf{u}\\Vert_2 \\Vert\\mathbf{v}\\Vert_2}\\text{, where } e_{pi} =\\begin{cases}1 &amp; \\text{if track $i$ in playlist $p$} \\\\0 &amp; \\text{otherwise}\\end{cases}}\\]여기서 inner product는 id를 one-hot-encoding했을 때의 값이다.그러나 knn.py에서는 one-hot-encoding을 사용하지 않고 두 playlist 사이의 교집합의 원소의 개수로 구했다.Neighbor 모델에서와는 다르게 여기서는 playlist-playlist similarity를 구한다.2.2 Weighting by Inverse Item Frequency (IDF)\\[\\scriptsize{s_{uv} = \\sum_{i \\in \\mathcal{T}} ((f_i - 1)^\\rho + 1)^{-1} \\cdot \\cfrac{e_{ui}e_{vi}}{\\Vert\\mathbf{u}\\Vert_2 \\Vert\\mathbf{v}\\Vert_2}}\\]where $f_i$ denotes the number of playlists containing track i and $rho$ is an hyperparameter. Two playlists are more likely similar if they include the same low popularity tracks than if they share tracks that a very large number of other lists also include.IDF를 사용했을 때 사용하지 않을 때보다 훨씬 성능이 좋았다.논문에서는 $\\rho = 0.4$를 사용해서 같은 $\\rho$ 값을 사용하였다.3. Relevance $r_{ui}$\\[\\scriptsize{r_{ui} = \\cfrac{\\sum_{v \\in N_k(u)} s_{uv} \\cdot e_{vi}}{\\sum_{v \\in N_k(u)} s_{uv}}}\\]where $N_k(u)$ is the set of $k$ playlists most similar to $u$.target playlist $u$에 대해 모든 playlist $v \\in \\mathcal{P}$와 similarity $s_{uv}$를 구한 다음 가장 similarity가 큰 상위 $k$로 $N_k(u)$를 정한다.그 $N_k(u)$를 사용해서 playlist-track relevance를 구한다.ModelingInput &amp; Output논문에서는 Song → Song (Tag → Tag)의 방법이지만 이와 같은 input &amp; output은 성능이 더 좋았던 Neighbor 모델을 사용했다.Neighbor에서 설명했듯이 Neighbor 모델은 한계가 있어서 이 점을 보완하기 위해 KNN 모델에서는 다음과 같은 예측 방식을 따른다. Song → Tag Tag   → Song즉, song only인 경우에 대해 song similarity 기반으로 유사한 playlist를 찾는다. 유사한 playlist에 있는 태그를 자주 등장한 순서대로 정렬한다. tag only인 경우에 대해 tag similarity 기반으로 유사한 playlist를 찾는다. 유사한 playlist에 있는 노래에 대해 relevance를 구해서 정렬한다.similarity를 구할 때 val.json (test.json)에 있는 song / tag와 Neighbor 모델의 예측 결과로 나온 pred song / tag를 사용한다.각 데이터셋에 대해 similarity를 각각 구하고 더하는데, 더할 때의 가중치도 hyperparameter로 설정하였다. $\\scriptsize{0 \\le \\text{(weight_val_songs)} \\le 1}$ (wvs) weight_pred_songs = 1 - weight_val_songs $\\scriptsize{0 \\le \\text{(weight_val_tags)} \\le 1}$ (wvt) weight_pred_tags    = 1 - weight_val_tags추가적으로, similarity를 구할 때 normalize 여부를 달리해서도 사용해봤다. 모델의 결과가 song 100개 tag 10개 미만이 되는 경우가 있어서 $k$를 늘릴 수 있는 step을 추가했다.Optimization hyperparameter optimal value song $k$ 500 tag $k$ 90 song step 50 tag step 10 sim song IDF sim tag IDF sim norm True wvs 0.9 wvt 0.7 아래에서 사용한 similarity 종류는 IDF, wvs = 0.9, wvt = 0.7이다.$\\alpha = 0.7$ &amp; $\\beta = 0.0$ &amp; sim norm = False$\\alpha = 0.7$ &amp; $\\beta = 0.0$ &amp; sim norm = True$\\alpha = 0.7$ &amp; $\\beta = 0.0$ &amp; sim norm = False &amp; using Threshold$\\alpha = 0.65$ &amp; $\\beta = 0.0$ &amp; sim norm = True &amp; using Thresholdsong $k$ = 100 &amp; tag $k$ = 100 &amp; song step = 10 &amp; tag step = 10CodeKNN.py import numpy as npimport pandas as pdfrom collections import Counterfrom data_util import tag_id_metaclass KNN: ''' K Nearest Neighbor ''' __version__ = \"KNN-2.0\" def __init__(self, song_k, tag_k, rho=0.4, \\ song_k_step=50, tag_k_step=10, \\ weight_val_songs=0.5, weight_pred_songs=0.5, \\ weight_val_tags=0.5, weight_pred_tags=0.5, \\ sim_songs=\"idf\", sim_tags=\"idf\", sim_normalize=False, \\ train=None, val=None, song_meta=None, pred=None): ''' song_k, tag_k, song_k_step, tag_k_step : int rho : float; 0.4(default) only for idf weights : float sim_songs, sim_tags : \"idf\"(default), \"cos\" sim_normalize : boolean; ''' ### data sets self.train_id = train[\"id\"].copy() self.train_songs = train[\"songs\"].copy() self.train_tags = train[\"tags\"].copy() self.val_id = val[\"id\"].copy() self.val_songs = val[\"songs\"].copy() self.val_tags = val[\"tags\"].copy() self.val_updt_date = val[\"updt_date\"].copy() self.song_meta_issue_date = song_meta[\"issue_date\"].copy().astype(np.int64) self.pred_songs = pred[\"songs\"].copy() self.pred_tags = pred[\"tags\"].copy() self.freq_songs = None self.freq_tags = None self.song_k = song_k self.tag_k = tag_k self.song_k_step = song_k_step self.tag_k_step = tag_k_step self.rho = rho self.weight_val_songs = weight_val_songs self.weight_pred_songs = weight_pred_songs self.weight_val_tags = weight_val_tags self.weight_pred_tags = weight_pred_tags self.sim_songs = sim_songs self.sim_tags = sim_tags self.sim_normalize = sim_normalize self.__version__ = KNN.__version__ _, id_to_tag = tag_id_meta(train, val) TOTAL_SONGS = song_meta.shape[0] # total number of songs TOTAL_TAGS = len(id_to_tag) # total number of tags ### transform date format in val for idx in self.val_id.index: self.val_updt_date.at[idx] = int(''.join(self.val_updt_date[idx].split()[0].split('-'))) self.val_updt_date.astype(np.int64) if self.sim_songs == \"idf\": self.freq_songs = np.zeros(TOTAL_SONGS, dtype=np.int64) for _songs in self.train_songs: self.freq_songs[_songs] += 1 if self.sim_tags == \"idf\": self.freq_tags = np.zeros(TOTAL_TAGS, dtype=np.int64) for _tags in self.train_tags: self.freq_tags[_tags] += 1 del train, val, song_meta, pred def predict(self): ''' @returns : pandas.DataFrame; columns=['id', 'songs', 'tags'] ''' _range = range(self.val_id.size) pred = [] all_songs = [set(songs) for songs in self.train_songs] # list of set all_tags = [set(tags) for tags in self.train_tags] # list of set for uth in _range: # predict songs by tags if self.val_songs[uth] == [] and self.val_tags[uth] != []: playlist_tags_in_pred = set(self.pred_tags[uth]) playlist_tags_in_val = set(self.val_tags[uth]) playlist_updt_date = self.val_updt_date[uth] simTags_in_pred = np.array([self._sim(playlist_tags_in_pred, vplaylist, self.sim_tags, opt='tags') for vplaylist in all_tags]) simTags_in_val = np.array([self._sim(playlist_tags_in_val , vplaylist, self.sim_tags, opt='tags') for vplaylist in all_tags]) simTags = ((self.weight_pred_tags * simTags_in_pred) / (len(playlist_tags_in_pred))) + \\ ((self.weight_val_tags * simTags_in_val) / (len(playlist_tags_in_val))) songs = set() try: song_k = min(len(simTags[simTags &gt; 0]), self.song_k) except: song_k = self.song_k while len(songs) &lt; 100: top = simTags.argsort()[-song_k:] _songs = [] for vth in top: _songs += self.train_songs[vth] songs = set(_songs) # check if issue_date of songs is earlier than updt_date of playlist date_checked = [] for track_i in songs: if self.song_meta_issue_date[track_i] &lt;= playlist_updt_date: date_checked.append(track_i) songs = set(date_checked) song_k += self.song_k_step norm = simTags[top].sum() if norm == 0: norm = 1.0e+10 # FIXME relevance = np.array([(song, np.sum([simTags[vth] if song in all_songs[vth] else 0 for vth in top]) / norm) for song in songs]) relevance = relevance[relevance[:, 1].argsort()][-100:][::-1] pred_songs = relevance[:, 0].astype(np.int64).tolist() pred.append({ \"id\" : int(self.val_id[uth]), \"songs\" : pred_songs, \"tags\" : self.pred_tags[uth] }) # predict tags using songs elif self.val_songs[uth] != [] and self.val_tags[uth] == []: playlist_songs_in_pred = set(self.pred_songs[uth]) playlist_songs_in_val = set(self.val_songs[uth]) simSongs_in_pred = np.array([self._sim(playlist_songs_in_pred, vplaylist, self.sim_songs, opt='songs') for vplaylist in all_songs]) simSongs_in_val = np.array([self._sim(playlist_songs_in_val , vplaylist, self.sim_songs, opt='songs') for vplaylist in all_songs]) simSongs = ((self.weight_pred_songs * simSongs_in_pred) / (len(playlist_songs_in_pred))) + \\ ((self.weight_val_songs * simSongs_in_val) / (len(playlist_songs_in_val))) tags = [] try: tag_k = min(len(simSongs[simSongs &gt; 0]), self.tag_k) except: tag_k = self.tag_k while len(tags) &lt; 10: top = simSongs.argsort()[-tag_k:] _tags = [] for vth in top: _tags += self.train_tags[vth] counts = Counter(_tags).most_common(30) tags = [tag for tag, _ in counts] tag_k += self.tag_k_step pred_tags = tags[:10] pred.append({ \"id\" : int(self.val_id[uth]), \"songs\" : self.pred_songs[uth], \"tags\" : pred_tags }) # if val.songs[uth] == [] and val.tags[uth] == [] -&gt; pred.songs[uth] == [] and pred.tags[uth] == [] # if val.songs[uth] != [] and val.tags[uth] != [] -&gt; pred.songs[uth] != [] and pred.tags[uth] != [] else: pred.append({ \"id\" : int(self.val_id[uth]), \"songs\" : self.pred_songs[uth], \"tags\" : self.pred_tags[uth] }) return pd.DataFrame(pred) def _sim(self, u, v, sim, opt): ''' u : set (playlist in train data) v : set (playlist in test data) sim : string; \"cos\", \"idf\" opt : string; \"songs\", \"tags\" ''' if sim == \"cos\": if self.sim_normalize: try: return len(u &amp; v) / ((len(u) ** 0.5) * (len(v) ** 0.5)) except: return 0 else: return len(u &amp; v) elif sim == \"idf\": if opt == \"songs\": freq = self.freq_songs elif opt == \"tags\": freq = self.freq_tags freq = freq[list(u &amp; v)] freq = 1 / (((freq - 1) ** self.rho) + 1) # numpy! if self.sim_normalize: try: return freq.sum() / ((len(u) ** 0.5) * (len(v) ** 0.5)) except: return 0 else: return freq.sum() More Ideas IDF 식에서 $((f_i - 1)^\\rho + 1)^{-1}$ 부분 변형하기 optimal $\\rho$ 찾기" }, { "title": "Melon Playlist Continuation - Model 1: Neighbor-based", "url": "/posts/melon-playlist-continuation-neighbor/", "categories": "Kakao Arena, Melon Playlist Continuation", "tags": "kakao arena, melon playlist continuation", "date": "2020-07-26 19:22:00 +0900", "snippet": "Reference[Paper] [Code] Automatic Music Playlist Continuation via Neighbor-based Collaborative Filtering and Discriminative ReweightingReranking (RecSys’18 Challenge)위의 논문을 바탕으로 Neighbor 모델을 만들었다.Process1. Notaion $\\mathcal{P}$ : All Playlists in train.json $\\mathcal{T}$ : All Tracks $u$ : Target Playlist in val.json or test.json $v$ : Candidate Playlist in train.json Known Track $j \\in u$ (same as $j \\in \\mathcal{T}(u)$) Candidate Track $i \\in v$ $\\mathcal{P}(i)$ : Playlists that contain track $i$ $\\mathcal{T}(u)$ : Tracks in playlist $u$ $\\mathbf{x}_i$ : Feature Vector for Candidate Track $i$ $s_{ij}$ : Similarity between Candidate Track $i$ and Known Track $j$ $r_{ui}$ : Relevance between Candidate Track $i$ and Target Playlist $u$ $\\alpha$, $\\beta$ : Hyperparameters2. Feature Vector $\\mathbf{x}_i$\\[\\scriptsize{(\\mathbf{x}_i)_{[v]} =\\begin{cases}\\cfrac{|\\mathcal{T}(u) \\cup \\mathcal{T}(v) | }{|\\mathcal{T}(v)|^\\alpha} &amp; \\scriptsize{\\text{if playlist $v$ contains track $i$}} \\\\0 &amp; \\scriptsize{\\text{else}}\\end{cases}}\\]where $0 \\le \\alpha \\le 1$ is a hyperparameter that controls the influence of long playlists.길이가 긴 playlist일수록 더 많은 track을 포함하고 많은 target playlist와 연관성이 높게 나온다. 많은 target playlist와 연관성이 높은 playlist는 특정 target playlist의 특성을 대표한다고 보기 어렵기 때문에 playlist 길이로 나눠주어 길이가 긴 playlist의 효과를 감소시켰다.$\\alpha \\rightarrow 0$일수록 playlist의 길이를 고려하지 않고 $\\alpha \\rightarrow 1$일수록 playlist의 길이를 많이 고려한다. 따라서 hyperparameter를 조절할 때 $0.5 \\sim 1.0$ 사이의 값을 우선적으로 사용하였다.feature vector $\\mathbf{x}_i$는 하나의 target playlist $u$와 하나의 candidate track $i$에서 모든 playlist $v \\in \\mathcal{P}$에 대해 구하기 때문에 shape은 다음과 같다.\\[\\scriptsize{\\mathbf{x}_i \\in \\mathbb{R}^{|\\mathcal{P}|}}\\]3. Similarity $s_{ij}$\\[\\scriptsize{s_{ij} = \\cfrac{(\\mathbf{x}_i)^T \\mathbf{x}_j}{|\\mathcal{P}(i)|^\\beta |\\mathcal{P}(j)|^{1-\\beta}}}\\]where $0 \\le \\beta \\le 1$ is hyperparameter.similarity는 feature vector $\\mathbf{x}_i$와 $\\mathbf{x}_j$를 내적해서 구한다.유의할 점은 위의 식은 playlist-track similarity가 아니라 track-track similarity라는 것이다.또한 track $i$를 포함하는 playlist 개수와 track $j$를 포함하는 playlist 개수로 나눠주는데 앞의 아이디어와 유사하다는 것을 알 수 있다.많은 playlist에 들어있는 track은 특정 playlist 몇 개에 들어있는 track보다 상대적으로 playlist의 특성을 대표하기 어렵다고 볼 수 있는데 이를 수식에 적용한 것 같다.다만 실제로 모델을 돌려보았을 때 $\\beta \\rightarrow 1$일수록 성능이 좋지 않았다.4. Relevance $r_{ui}$\\[\\scriptsize{r_{ui} = \\frac{1}{|\\mathcal{T}(u)|} \\sum_{j \\in \\mathcal{T}(u)} s_{ij}}\\]track $j \\in |\\mathcal{T}(u)|$에 대해 앞에서 구한 similarity를 평균을 낸다.이 값이 playlist $u$에 대한 track $i$의 relevance이다.모든 track에 대한 relevance를 구하고 여기서 가장 높은 $m$개를 순서대로 구하면 된다.song에 대한 모델에서는 $m = 100$, tag에 대한 모델에서는 $m = 10$이 된다.논문은 track에 대해 사용을 했는데 여기서는 tag도 예측을 해야하므로 song과 tag 두 경우에 대해 동일하게 모델을 사용하였다.ModelingInput &amp; OutputNeighbor 모델은 앞에서 설명한 방법으로 다음과 같은 예측을 한다. Song → Song Tag   → Tag여기서 Song이나 Tag가 비어있으면 비어있는 playlist에 대한 예측 결과는 모두 같을 것이다.따라서 Song이나 Tag가 비어있지 않아야 예측의 의미가 있다.Overview에서 구분한 각 case에 대한 ouput은 다음과 같다. case input output case 1 songs &amp; tags songs &amp; tags case 2 songs only songs only case 3 tags only tags only case 4 no songs &amp; no tags none song이 있는 경우에는 song을 예측하고 tag가 있는 경우에는 tag를 예측한다.예측하지 못한 경우에 대해서는 KNN을 사용한다.Optimization hyperparameter optimal value $\\alpha$ 0.65 $\\beta$ 0.0 (heatmap에는 $\\alpha = 0.65$인 결과 없음.)CodeNeighbor.py import numpy as npimport pandas as pdfrom data_util import tag_id_metaclass Neighbor: ''' Neighbor-based Collaborative Filtering ''' __version__ = \"Neighbor-3.0\" def __init__(self, pow_alpha, pow_beta, train=None, val=None, song_meta=None): ''' pow_alpha, pow_beta : float (0&lt;= pow_alpha, pow_beta &lt;= 1) train, val, song_meta : pandas.DataFrame ''' ### 1. data sets self.train_id = train[\"id\"].copy() self.train_songs = train[\"songs\"].copy() self.train_tags = train[\"tags\"].copy() self.val_id = val[\"id\"].copy() self.val_songs = val[\"songs\"].copy() self.val_tags = val[\"tags\"].copy() self.val_updt_date = val[\"updt_date\"].copy() self.song_meta_issue_date = song_meta[\"issue_date\"].copy().astype(np.int64) ### ?. parameters self.pow_alpha = pow_alpha self.pow_beta = pow_beta self.__version__ = Neighbor.__version__ if not (0 &lt;= self.pow_alpha &lt;= 1): raise ValueError('pow_alpha is out of [0,1].') if not (0 &lt;= self.pow_beta &lt;= 1): raise ValueError('pow_beta is out of [0,1].') _, id_to_tag = tag_id_meta(train, val) TOTAL_SONGS = song_meta.shape[0] # total number of songs TOTAL_TAGS = len(id_to_tag) # total number of tags TOTAL_PLAYLISTS = train.shape[0] # total number of playlists ### 2. data preprocessing ### 2.1 transform date format in val for idx in self.val_id.index: self.val_updt_date.at[idx] = int(''.join(self.val_updt_date[idx].split()[0].split('-'))) self.val_updt_date.astype(np.int64) ### 2.2 count frequency of songs in train and compute matrices freq_songs = np.zeros(TOTAL_SONGS, dtype=np.int64) for _songs in self.train_songs: freq_songs[_songs] += 1 MAX_SONGS_FREQ = np.max(freq_songs) self.freq_songs_powered_beta = np.power(freq_songs, self.pow_beta) self.freq_songs_powered_another_beta = np.power(freq_songs, 1 - self.pow_beta) ### 2.3 count frequency of tags in train and compute matrices freq_tags = np.zeros(TOTAL_TAGS, dtype=np.int64) for _tags in self.train_tags: freq_tags[_tags] += 1 MAX_TAGS_FREQ = np.max(freq_tags) self.freq_tags_powered_beta = np.power(freq_tags, self.pow_beta) self.freq_tags_powered_another_beta = np.power(freq_tags, 1 - self.pow_beta) ### constants self.TOTAL_SONGS = TOTAL_SONGS self.MAX_SONGS_FREQ = MAX_SONGS_FREQ self.TOTAL_TAGS = TOTAL_TAGS self.MAX_TAGS_FREQ = MAX_TAGS_FREQ self.TOTAL_PLAYLISTS = TOTAL_PLAYLISTS del train, val, song_meta def predict(self): ''' @returns : pandas.DataFrame; columns=['id', 'songs', 'tags'] ''' _range = range(self.val_id.size) pred = [] all_songs = [set(songs) for songs in self.train_songs] # list of set all_tags = [set(tags) for tags in self.train_tags ] # list of set TOTAL_SONGS = self.TOTAL_SONGS # total number of songs MAX_SONGS_FREQ = self.MAX_SONGS_FREQ # max frequency of songs for all playlists in train TOTAL_TAGS = self.TOTAL_TAGS # total number of tags MAX_TAGS_FREQ = self.MAX_TAGS_FREQ # max frequency of tags for all playlists in train TOTAL_PLAYLISTS = self.TOTAL_PLAYLISTS # total number of playlists for uth in _range: playlist_songs = set(self.val_songs[uth]) playlist_tags = set(self.val_tags[uth]) playlist_updt_date = self.val_updt_date[uth] # type : np.int64 playlist_size_songs = len(playlist_songs) playlist_size_tags = len(playlist_tags) pred_songs = [] pred_tags = [] if playlist_size_songs == 0 and playlist_size_tags == 0: pred.append({ \"id\" : int(self.val_id[uth]), \"songs\" : [], \"tags\" : [] }) continue # predict songs if playlist_size_songs != 0: track_feature = {track_i : {} for track_i in range(TOTAL_SONGS)} relevance = np.concatenate((np.arange(TOTAL_SONGS).reshape(TOTAL_SONGS, 1), np.zeros((TOTAL_SONGS, 1))), axis=1) # feature vector for vth, vplaylist in enumerate(all_songs): intersect = len(playlist_songs &amp; vplaylist) weight = 1 / (pow(len(vplaylist), self.pow_alpha)) if intersect != 0: for track_i in vplaylist: track_feature[track_i][vth] = intersect * weight # similarity and relevance for track_i in range(TOTAL_SONGS): feature_i = track_feature[track_i] if (feature_i != {}) and (not track_i in playlist_songs): contain_i = self.freq_songs_powered_beta[track_i] sum_of_sim = 0 for track_j in playlist_songs: feature_j = track_feature[track_j] contain_j = self.freq_songs_powered_another_beta[track_j] contain = contain_i * contain_j if contain == 0: contain = 1.0e-10 sum_of_sim += (self._inner_product_feature_vector(feature_i, feature_j) / contain) relevance[track_i, 1] = (1 / playlist_size_songs) * sum_of_sim # sort relevance relevance = relevance[relevance[:, 1].argsort()][::-1] sorted_songs = relevance[:, 0].astype(np.int64).tolist() # check if issue_date of songs is earlier than updt_date of playlist for track_i in sorted_songs: if self.song_meta_issue_date[track_i] &lt;= playlist_updt_date: pred_songs.append(track_i) if len(pred_songs) == 100: break # predict tags if playlist_size_tags != 0: track_feature = {track_i : {} for track_i in range(TOTAL_TAGS)} relevance = np.concatenate((np.arange(TOTAL_TAGS).reshape(TOTAL_TAGS, 1), np.zeros((TOTAL_TAGS, 1))), axis=1) # feature vector for vth, vplaylist in enumerate(all_tags): intersect = len(playlist_tags &amp; vplaylist) weight = 1 / (pow(len(vplaylist), self.pow_alpha)) if intersect != 0: for track_i in vplaylist: track_feature[track_i][vth] = intersect * weight # similarity and relevance for track_i in range(TOTAL_TAGS): feature_i = track_feature[track_i] if (feature_i != {}) and (not track_i in playlist_tags): contain_i = self.freq_tags_powered_beta[track_i] sum_of_sim = 0 for track_j in playlist_tags: feature_j = track_feature[track_j] contain_j = self.freq_tags_powered_another_beta[track_j] contain = contain_i * contain_j if contain == 0: contain = 1.0e-10 sum_of_sim += (self._inner_product_feature_vector(feature_i, feature_j) / contain) relevance[track_i, 1] = (1 / playlist_size_tags) * sum_of_sim # select top 10 relevance = relevance[relevance[:, 1].argsort()][-10:][::-1] pred_tags = relevance[:, 0].astype(np.int64).tolist() pred.append({ \"id\" : int(self.val_id[uth]), \"songs\" : pred_songs, \"tags\" : pred_tags }) return pd.DataFrame(pred) def _inner_product_feature_vector(self, v1, v2): ''' v1, v2 : dictionary(key=vplaylist_id, val=features) ''' result = 0 for key, val in v1.items(): if key in v2: result += (v1[key] * v2[key]) return resultif __name__==\"__main__\": pass from data_util.py import tag_id_meta import pandas as pddef tag_id_meta(train, val): ''' train, val : list of pandas.DataFrame @returns : (dictionary, dictionary) ''' tag_to_id = {} id_to_tag = {} data = [train, val] tag_id = 0 for df in data: for idx in df.index: for tag in df[\"tags\"][idx]: if tag not in tag_to_id: tag_to_id[tag] = tag_id id_to_tag[tag_id] = tag tag_id += 1 return tag_to_id, id_to_tag train.json과 val.json에 있는 태그에 대한 두 개의 딕셔너리를 반환한다. tag_to_id : key = tag, value = id id_to_tag : key = id,   value = tag More Ideas Reweight &amp; Reranking" }, { "title": "Melon Playlist Continuation - Overview", "url": "/posts/melon-playlist-continuation-overview/", "categories": "Kakao Arena, Melon Playlist Continuation", "tags": "kakao arena, melon playlist continuation", "date": "2020-07-26 19:20:00 +0900", "snippet": "Project RepositoryGoal주어진 playlist에 대해 songs 100개, tags 10개를 순서에 맞게 예측해야 한다.Predict additional 100 songs and 10 tags in orderly-correct way for all given playlists.Data대회에서 주어진 데이터는 크게 두가지 였다. User data : List of playlists, Song meta data Item data : Spectrogram of 707989 songs (about 232 GB)Spectrogram은 용량이 너무 커서 사용하지 못했고 사용자 기반의 데이터만을 사용하였다.Models다음 두가지 모델을 사용했다. K Nearest Neighbor Another Neighbor-based Model (Simply called it Neighbor.)EDAGroup by Casesval.json과 test.json의 각 playlist를 title, songs, tags의 유무로 분류하면 그 비율은 다음과 같다. Title Songs Tags val.json (%) test.json (%) X X X 0 0 X X O 0 0 X O X 42 42 X O O 39 39 O X X 8 8 O X O 11 11 O O X 0 0 O O O 0 0 Reference에서 사용한 모델에 적용하기 위해 다음과 같이 case를 나눴다.case: songs &amp; tags songs only tags only title only = no songs &amp; no tags단, case 1, 2, 3에 대해 title은 있더라도 무시한다.case 1에 대해서는 Neighbor을 사용한다.case 2, 3에 대해서는 Neighbor을 사용한 후에 KNN을 사용한다.case 4에 대해서는 title에서 미리 tag를 추출하여 case 1 or case 3으로 변형한다.IdeasIssue Date &amp; Update DateCandidate songs whose issue date is earlier than update date of the given playlist are excluded.From this, the model performed 0.0027 higher than before about total score.0.0027 improvement about total score is eqaul to 0.0039 improvement about song nDCG score." }, { "title": "Lattice Laplacian on 2D Boundary", "url": "/posts/lattice-laplacian/", "categories": "Mathematics, Computational Mathematics", "tags": "mathematics, python", "date": "2020-01-20 00:00:00 +0900", "snippet": "1. Problem$0 &lt; x &lt; 2$ $0 &lt; y &lt; 2$인 정사각형 영역에서 Laplace equation을 만족하는 $u(x,y)$에 대하여 다음과 같은 boundary condition을 만족한다고 하자.Boundary condition: $x=0 \\rightarrow u=0$ $x=2 \\rightarrow u=0$ $y=0 \\rightarrow u=0$ $y=2 \\rightarrow u=f(x)$ where $f(x)=\\sin\\frac{\\pi x}{2}$\\[\\nabla^{2}u(x,y)=0 \\tag{1}\\]\\[\\frac{\\partial^{2}u}{\\partial x^{2}} + \\frac{\\partial^{2}u}{\\partial y^{2}} = 0 \\tag{2}\\]2. Analytical Solution2.1 Separation of Variables\\(u(x,y) = X(x)Y(y) \\tag{3}\\)$X(x)Y(y)$를 $(2)$에 대입하면\\[Y(y)\\frac{d^{2}X(x)}{d x^{2}} + X(x)\\frac{d^{2}Y(y)}{d y^{2}} = 0 \\tag{4}\\]$(4)$의 양변을 $(3)$으로 나누어주면\\[\\frac{1}{X(x)}\\frac{d^{2}X(x)}{d x^{2}} = - \\frac{1}{Y(y)}\\frac{d^{2}Y(y)}{d y^{2}} = -k^{2} = const. \\tag{5}\\]where $k&gt;0$.\\[\\therefore X(x) = A\\sin kx +B\\cos kx \\quad Y(y) = Ce^{ky} + De^{-ky} \\tag{6}\\]2.2 Boundary Condition 1Boundary Condition 1에 의해 $u(x=0, y) = X(x=0)Y(y) = 0$을 $y$에 상관없이 만족해야 하므로\\[\\therefore X(x)=A\\sin kx \\tag{7}\\]2.3 Boundary Condition 2Boundary Condition 2에 의해 $u(x=2, y) = X(x=2)Y(y) = 0$을 $y$에 상관없이 만족해야 하므로 $X(x=2)=A\\sin{2k}=0$이 성립한다.\\[\\therefore k = \\frac{n\\pi}{2} \\ (n = 1, 2, 3, \\ldots) \\tag{8}\\]$(6), (7), (8)$을 $(3)$에 대입하면\\[u_{n}(x,y)=(C_{n}e^{\\frac{n\\pi}{2}y} + D_{n}e^{-\\frac{n\\pi}{2}y})\\sin{\\frac{n\\pi}{2}x} \\tag{9}\\]2.4 Boundary Condition 3Boundary Condition 3에 의해 $u_{n}(x,y=0) = (C_{n} + D_{n})\\sin{\\frac{n\\pi}{2}x} = 0$을 $x$에 상관없이 만족해야 하므로 $C_{n} + D_{n} = 0$이 성립한다.\\[\\therefore D_{n} = - C_{n} \\tag{10}\\]\\[\\therefore u_{n}(x,y)=C_{n}(e^{\\frac{n\\pi}{2}y} - e^{-\\frac{n\\pi}{2}y})\\sin{\\frac{n\\pi}{2}x} \\tag{11}\\]미분 연산은 linear하고 따라서 Laplacian $\\nabla^{2}$도 linear한 operation이므로 Laplace equation $(1)$을 만족하는 general solution $u(x,y) = \\sum_{n=1}^{\\infty} u_{n}(x,y)$는 다음과 같이 쓸 수 있다.\\[u(x,y) = \\sum_{n=1}^{\\infty} C_{n}(e^{\\frac{n\\pi}{2}y} - e^{-\\frac{n\\pi}{2}y})\\sin{\\frac{n\\pi}{2}x} \\tag{12}\\]2.5 Boundary Condition 4: Fourier SeriesBoundary Condition 4에 의해 $u(x,y=2) = f(x) = \\sin{\\frac{\\pi x}{2}}$를 만족해야 하므로\\[u(x,y=2) = \\sum_{n=1}^{\\infty} C_{n}(e^{n\\pi} - e^{-n\\pi})\\sin{\\frac{n\\pi}{2}x} = \\sin{\\frac{\\pi x}{2}} \\tag{13}\\]Let $c_{n} = C_{n}(e^{n\\pi} - e^{-n\\pi})$ and $(13)$ will be a Fourier series form with period $l = 2$.\\[\\therefore u(x,2) = \\sum_{n=1}^{\\infty} c_{n}\\sin{\\frac{n\\pi}{2}x} = \\sin{\\frac{\\pi x}{2}} \\tag{14}\\]where $u(x,2)$ is a function of $x$.Fourier series에 의하여 $c_{n} = \\frac{2}{l} \\int_{0}^{l} f(x)\\sin{\\frac{n\\pi}{l}x}dx = \\int_{0}^{2} \\sin{\\frac{\\pi x}{2}}\\sin{\\frac{n\\pi}{l}x}dx = 0 \\ (n \\neq 1)$.\\[\\therefore C_{n}=0 \\ (n \\neq 1) \\tag{15}\\]For $n=1$, $c_1 = \\frac{2}{l} \\int_{0}^{l} f(x)\\sin{\\frac{\\pi}{l}x}dx = \\int_{0}^{2} \\sin^{2}{\\frac{\\pi}{2}x}dx = 0$.\\[\\therefore C_1 = \\frac{1}{e^{\\pi} - e^{-\\pi}} \\tag{16}\\]2.6 Solution$(12)$와 $(15), (16)$에 의하여\\[\\therefore u(x,y) = \\frac{1}{e^{\\pi} - e^{-\\pi}}(e^{\\frac{\\pi}{2}y} - e^{-\\frac{\\pi}{2}y})\\sin{\\frac{\\pi}{2}x} \\tag{17}\\]3. Numerical SolutionLet’s solve numerically above problem and draw graphs using Python library numpy and matplotlib.3.1 What is Lattice Laplacian?미적분 시간에 배웠던 리만 합과 비슷하다.그래프를 연속적인 선 또는 면으로 생각하지 않고 잘게 조각내어 (Lattice) 각 조각에 대해 계산을 하는 것이다.당연히 조각의 수가 클수록 계산 결과는 참 값에 가까워 진다.여기서는 단지 조각을 나누는 것을 Laplacian을 계산하는데 사용하는 것 뿐이다.3.2 Basic SettingsI used Jupyter Notebook.import math, randomimport numpy as npfrom matplotlib import pyplot as pltN = 100 # divide area into N equal partse = [10 ** i for i in range(5)] # epochx_left, x_right = 0, 2 # x coordinates 0 &lt; x &lt; 2y_left, y_right = 0, 2 # y coordinates 0 &lt; y &lt; 2영역을 $x$축 방향으로 N만큼 $y$축 방향으로 N만큼 동일한 크기의 블럭으로 나눌 것이다.따라서 총 N$^{2}$개의 블럭이 생긴다. N = 100이므로 영역을 총 10000개의 동일한 크기의 블럭으로 나누게 된다.각각의 블럭에는 하나의 실수값이 배치된다.def boundary_f(j): return math.sin(math.pi * j / (N-1)) if j != N-1 else 0def Lattice(coor, i, j): return (coor[i+1,j] + coor[i-1,j] + coor[i,j+1] + coor[i,j-1]) / 4def to_matrix(maths): return maths * (N-1) / 2def to_maths(matrix_idx): return matrix_idx * 2 / (N-1)'''to_matrix and to_maths are used to transform two different scales.'''3.3 Coordinates InitialisationBoundary Condition 1, 2, 3에 의하여 $x \\times y = 0$ or $x = 2$일 때 $u = 0$이다.coordinates = np.matrix([ [ 0 if i * j == 0 or j == 99 else random.random() for j in range(N) ] for i in range(N)])print(coordinates)print(np.shape(coordinates))&gt;&gt;&gt;[[0. 0. 0. ... 0. 0. 0. ] [0. 0.76647573 0.85497858 ... 0.65825655 0.70332986 0. ] [0. 0.08536608 0.15863341 ... 0.76746172 0.06642089 0. ] ... [0. 0.01348908 0.74033728 ... 0.67932431 0.25610339 0. ] [0. 0.26472592 0.4982553 ... 0.67932193 0.82749659 0. ] [0. 0.37740627 0.06626904 ... 0.33949001 0.65761649 0. ]] (100, 100)$(i,j)$ coordinates 행렬의 $(0,0) \\ldots (99,99)$에 boundary condition에 맞는 $u(i,j)$ 값들을 대입한 결과이다. 첫번째 행과 열의 index는 0부터 시작한다고 한다. 이때 $(i=0, j)$는 $y=0 \\ \\text{(x-axis)}$이고 $(i, j=0)$, $(i, j=0)$는 각각 $x=0 \\ \\text{(y-axis)}$, $x=2$이다. 좌우는 동일하고 상하는 대칭이라고 생각하면 쉽다.경계가 아닌 영역의 값들은 random.random 함수를 이용해 임의로 설정하였다. random.random 함수의 범위는 $[0,1)$이다.for j in range(N): coordinates[N-1,j] = boundary_f(j)print(coordinates)print(np.shape(coordinates))&gt;&gt;&gt;[[0. 0. 0. ... 0. 0. 0. ] [0. 0.76647573 0.85497858 ... 0.65825655 0.70332986 0. ] [0. 0.08536608 0.15863341 ... 0.76746172 0.06642089 0. ] ... [0. 0.01348908 0.74033728 ... 0.67932431 0.25610339 0. ] [0. 0.26472592 0.4982553 ... 0.67932193 0.82749659 0. ] [0. 0.03172793 0.06342392 ... 0.06342392 0.03172793 0. ]](100, 100)99행$(i, j=99)$의 값들은 Boundary Condition 4에 맞게 초기화 되었다. 이제 경계값들을 모두 초기화 하였으므로 Lattice Laplacian 방법을 사용하여 영역 내부의 값들을 Laplace equation의 해가 되도록 계산할 것이다.3.4 Lattice Laplacianfor iteration in range(M[4]): # M[4] == 10000 updated = coordinates.copy() for i in range(1,N-1): for j in range(1,N-1): updated[i,j] = Lattice(coordinates, i, j) # main algorithm coordinates = updated.copy()print(coordinates)Lattice Laplacian 방법으로 계산하기 위해 Lattice 함수가 사용되었다.&gt;&gt;&gt;[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00 0.00000000e+00 0.00000000e+00] [0.00000000e+00 9.05149261e-05 1.80482124e-04 ... 1.80938235e-04 9.02863769e-05 0.00000000e+00] [0.00000000e+00 1.80657748e-04 3.62046303e-04 ... 3.61133027e-04 1.81113859e-04 0.00000000e+00] ... [0.00000000e+00 2.97760537e-02 5.95212127e-02 ... 5.95221245e-02 2.97755968e-02 0.00000000e+00] [0.00000000e+00 3.07362940e-02 6.14420957e-02 ... 6.14416388e-02 3.07365222e-02 0.00000000e+00] [0.00000000e+00 3.17279335e-02 6.34239197e-02 ... 6.34239197e-02 3.17279335e-02 0.00000000e+00]]3.5 Comparison이제 Lattice Laplacian 방법으로 계산한 numerical solution과 analytical solution을 비교해보자. 해는 2차원이므로 한눈에 보기위해 $y=x$ 상의 대각성분만 비교한다.# diagonal components of numerical solutionnumerical_D = [ coordinates[k,k] for k in range(N) ]print(numerical_D)&gt;&gt;&gt;[0.0, 9.051492612165759e-05, 0.00036204630303846545, 0.0008145536264188748, 0.0014479683888704415, 0.002262192578925126, 0.0032570965781172296, 0.004432516454671923, 0.0057882506519266064, 0.007324056069232347, 0.009039643532732965, 0.010934672653099383, 0.013008746067011209, 0.015261403058930425, 0.017692112559508054, 0.02030026551680779, 0.023085166636425375, 0.026046025486532558, 0.02918194696388458, 0.032491921116903445, 0.035974812322090176, 0.03962934781023135, 0.04345410553915224, 0.04744750141013394, 0.05160777582555922, 0.05593297958588381, 0.060420959124650356, 0.06506934108097397, 0.069875516209734, 0.07483662263061025, 0.07994952841810309, 0.085210813535783, 0.09061675111922281, 0.09616328811338223, 0.10184602527163852, 0.10766019652519125, 0.11360064773321746, 0.1196618148259129, 0.12583770135443223, 0.132121855463733, 0.13850734630643857, 0.14498673991806288, 0.15155207457628878, 0.158194835669457, 0.16490593010201152, 0.17167566026735373, 0.17849369762138528, 0.18534905589296713, 0.19223006397058925, 0.1991243385077322, 0.20601875629270433, 0.21289942643216264, 0.21975166240105992, 0.22655995401541534, 0.23330793938806976, 0.23997837693146368, 0.24655311747546033, 0.2530130765723304, 0.25933820706520894, 0.265507472000634, 0.27149881797017145, 0.27728914897062185, 0.2828543008768861, 0.2881690166262365, 0.29320692221749056, 0.29794050363341684, 0.30234108479960475, 0.306378806698003, 0.3100226077583663, 0.31324020565593985, 0.3159980806488562, 0.31826146059390104, 0.3199943077845279, 0.32115930776025226, 0.32171786024182647, 0.3216300723518796, 0.3208547542859944, 0.31934941760447066, 0.31707027632029117, 0.3139722509640386, 0.31000897581171327, 0.30513280946654564, 0.299294848990984, 0.2924449477900469, 0.28453173745214794, 0.27550265375831606, 0.26530396707543297, 0.2538808173536666, 0.2411772539526924, 0.2271362805255342, 0.21169990519290705, 0.19480919624479515, 0.17640434360961552, 0.15642472633469295, 0.13480898632487665, 0.11149510858894163, 0.08642050824591851, 0.05952212454565295, 0.03073652215969229, 0.0]# diagonal curve of analytical solutiondef analytical_curve(x) : return (1 / (math.exp(math.pi) - math.exp(-math.pi))) * (math.exp(math.pi * x / 2) - math.exp(-math.pi * x / 2) ) * math.sin(math.pi * x / 2)same as\\[u(x,y=x) = \\frac{1}{e^\\pi - e^{-\\pi}} (e^{\\frac{\\pi}{2}x} - e^{-\\frac{\\pi}{2}x}) \\sin{\\frac{\\pi}{2}x} \\tag{18}\\]# diagonal components of analytical solutionanalytical_D = [analytical_curve(to_maths(i)) for i in range(N)]print(analytical_D)여기서 range(N) = [0, 1, 2, 3, …, N] scale을 $0 &lt; x &lt; 2$ or $0 &lt; y &lt; 2$ scale로 변환하기 위해 to_maths 함수가 사용되었다.&gt;&gt;&gt;[0.0, 8.719564034953965e-05, 0.000348782502451089, 0.0007847600557810537, 0.0013951262371926453, 0.0021798756825077846, 0.003138997250757162, 0.004272470841091858, 0.005580263502413895, 0.007062324835809864, 0.008718581689924405, 0.010548932149481523, 0.012553238817254581, 0.014731321389902822, 0.01708294852823681, 0.01960782902264963, 0.022305602254658084, 0.02517582795574172, 0.02821797526494911, 0.03143141108706486, 0.03481538775349818, 0.038369029988469715, 0.04209132118353773, 0.04598108898402343, 0.050036990191468796, 0.05425749498689222, 0.05864087048030098, 0.06318516359267706, 0.06788818327747664, 0.07274748208957724, 0.07776033711057267, 0.08292373024035567, 0.08823432786604633, 0.09368845992052209, 0.09928209834408527, 0.10501083496416883, 0.1108698588094348, 0.11685393287615993, 0.12295737036643943, 0.12917401041946688, 0.13549719335897334, 0.1419197354818319, 0.14843390341485826, 0.1550313880689629, 0.16170327822203961, 0.16844003376431332, 0.1752314586423092, 0.18206667354015907, 0.1889340883396197, 0.19582137440295191, 0.20271543672568848, 0.20960238600931966, 0.2164675107070291, 0.22329524909883774, 0.2300691614558475, 0.23677190235672393, 0.2433851932231207, 0.24988979514441964, 0.25626548206594685, 0.26249101441871997, 0.2685441132727842, 0.2744014351003073, 0.28003854723881805, 0.2854299041492907, 0.2905488245681944, 0.2953674696571421, 0.29985682225837657, 0.303986667369028, 0.30772557395185623, 0.31104087820504595, 0.31389866841855957, 0.31626377154954427, 0.3180997416543604, 0.31936885031990225, 0.3200320792420534, 0.3200491151043135, 0.3193783469148662, 0.3179768659656088, 0.3158004685819258, 0.3128036618372501, 0.3089396724117084, 0.3041604587793692, 0.2984167269138126, 0.2916579497068696, 0.2838323903004722, 0.27488712953653843, 0.26476809773473436, 0.25342011101273926, 0.2407869123683057, 0.22681121774692625, 0.2114347673232622, 0.19459838222865572, 0.17624202696100233, 0.156304877716977, 0.13472539689009128, 0.11144141398123564, 0.08639021317126809, 0.05950862780776092, 0.030733142060230534, 1.2246467991473532e-16]이제 그래프를 그려서 눈으로 비교해보자.plt.plot(range(N), numerical_D, color='blue', label='numerical solution')plt.plot(range(N), analytical_D, color='orange', label='analytical solution')plt.xlabel(\"y == x\")plt.ylabel(\"u(x,x)\")plt.title(\"Iteration = 10000\")plt.legend(loc=2)plt.show()파란색 그래프가 주황색 그래프에 잘 근사되었음을 알 수 있다.3.6 Graph by IterationIteration = 10, 100, 1000, 10000 일 때의 각각의 그래프이다. Iteration 횟수가 증가함에 따라 analytical solution에 점점 다가가는 것을 볼 수 있다." } ]
